{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_map(id, hash, download_url, ranked_playlist):\n",
    "    # Download map from URL\n",
    "    r = requests.get(download_url)\n",
    "    zip = zipfile.ZipFile(BytesIO(r.content))\n",
    "\n",
    "    # Find Info.dat and load it for song/author info and level .dat file names\n",
    "    files = zip.namelist()\n",
    "    info_file = None\n",
    "    if 'Info.dat' in files:\n",
    "        info_file = 'Info.dat'\n",
    "    elif 'info.dat' in files:\n",
    "        info_file = 'info.dat'\n",
    "    else:\n",
    "        print('can\\'t find Info.dat')\n",
    "        return\n",
    "    mapset_info = json.load(zip.open(info_file))\n",
    "\n",
    "    dir_name = f'{id} ({mapset_info[\"_songName\"]} - {mapset_info[\"_levelAuthorName\"]})'\n",
    "    dir_name = re.sub(r'[\\/:*?\"<>|]', '', dir_name) # Conform to file naming rules\n",
    "    save_path = os.path.join('./accsaber-maps/', dir_name)\n",
    "\n",
    "    # Find file names of ranked difficulties and extract\n",
    "    playlist_song = next((x for x in ranked_playlist['songs'] if x['hash'].lower() == hash))\n",
    "    for difficulty in playlist_song['difficulties']:\n",
    "        standard_characterisitic = next((x for x in mapset_info['_difficultyBeatmapSets'] if x['_beatmapCharacteristicName'] == 'Standard'))\n",
    "        diff_name = difficulty['name'][0].upper() + difficulty['name'][1:]\n",
    "        file = next((x['_beatmapFilename'] for x in standard_characterisitic['_difficultyBeatmaps'] if x['_difficulty'] == diff_name))\n",
    "        zip.extract(file, path=save_path)\n",
    "    \n",
    "    # Store hash and save Info.dat\n",
    "    mapset_info['_hash'] = hash\n",
    "    with open(os.path.join(save_path, 'Info.dat'), 'w') as f:\n",
    "        f.write(json.dumps(mapset_info))\n",
    "    \n",
    "    zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccSaber Ranked Map Downloader!\n",
      "Downloading non reupped maps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [01:45<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading reupped maps (may not work)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "print('AccSaber Ranked Map Downloader!')\n",
    "r = requests.get('https://api.accsaber.com/playlists/overall')\n",
    "playlist = json.load(BytesIO(r.content))\n",
    "\n",
    "all_hashes = list(map(lambda x: x['hash'].lower(), playlist['songs'])) # Reduce playlist to hash list\n",
    "hashes_2d = [all_hashes[i:i + 50] for i in range(0, len(all_hashes), 50)] # Split into up to 50 long hash arrays\n",
    "\n",
    "# Get info including download links for maps\n",
    "beatsaver_maps = []\n",
    "for hashes in hashes_2d:\n",
    "    r = requests.get(f'https://api.beatsaver.com/maps/hash/{\"%2C\".join(hashes)}')\n",
    "    maps = json.loads(r.text)\n",
    "    beatsaver_maps += maps.values()\n",
    "\n",
    "# Filter out reupped maps\n",
    "returned_hashes = [x['versions'][0]['hash'].lower() for x in beatsaver_maps]\n",
    "beatsaver_maps = [x for x in beatsaver_maps if x['versions'][0]['hash'].lower() in all_hashes]\n",
    "\n",
    "# Download and extract non reupped maps\n",
    "print('Downloading non reupped maps...')\n",
    "for beatsaver_map in tqdm(beatsaver_maps):\n",
    "    try:\n",
    "        download_and_extract_map(beatsaver_map['id'], beatsaver_map['versions'][0]['hash'].lower(), beatsaver_map['versions'][0]['downloadURL'], playlist)\n",
    "    except:\n",
    "        print(f'Error downloading {beatsaver_map[\"id\"]}')\n",
    "\n",
    "# Download and extract reupped maps\n",
    "print('Downloading reupped maps (may not work)...')\n",
    "reupped_hashes = [x for x in all_hashes if x not in returned_hashes]\n",
    "for hash in tqdm(reupped_hashes):\n",
    "    try:\n",
    "        r = requests.get(f'https://api.beatsaver.com/maps/hash/{hash}')\n",
    "        id = json.loads(r.text)['id']\n",
    "        download_url = f'http://cdn.beatsaver.com/{hash}.zip'\n",
    "        download_and_extract_map(id, hash, download_url, playlist)\n",
    "    except:\n",
    "        print(f'Error downloading {hash}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55b5f8c764ff5ae90d541e9e56dff8191bc47bdedc5c3d760a867f53a28dc58c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
